{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19/2/11 시작 \n",
    "# 튜토리얼\n",
    "# https://www.tensorflow.org/tutorials/estimators/cnn\n",
    "# 전체코드\n",
    "# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function    #??\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)    #??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Dense Layer\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])\n",
    "  }\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data\n",
    "((train_data, train_labels),\n",
    " (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data/np.float32(255)\n",
    "train_labels = train_labels.astype(np.int32)  # not required\n",
    "\n",
    "eval_data = eval_data/np.float32(255)\n",
    "eval_labels = eval_labels.astype(np.int32)  # not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efe7e7998d0>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/mnist_convnet_model', '_train_distribute': None, '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.08992168 0.11304546 0.11047923 0.09911022 0.11428747 0.09890474\n",
      "  0.09967223 0.08718351 0.09455034 0.09284515]\n",
      " [0.1099833  0.10487646 0.0931113  0.09168807 0.10179569 0.09661627\n",
      "  0.09909187 0.09640751 0.09953937 0.10689017]\n",
      " [0.11912756 0.11543614 0.08825264 0.08629337 0.09143274 0.1260003\n",
      "  0.09850322 0.09047842 0.09629846 0.0881771 ]\n",
      " [0.0956451  0.10588389 0.09759115 0.09773833 0.11112643 0.10940795\n",
      "  0.08864922 0.09605192 0.09578503 0.10212102]\n",
      " [0.10738832 0.11225307 0.09542951 0.09506106 0.0962492  0.1042496\n",
      "  0.09528075 0.09530737 0.09989766 0.09888343]\n",
      " [0.09838872 0.10431218 0.09310383 0.08295362 0.1135073  0.10473835\n",
      "  0.09158159 0.09746857 0.11369053 0.10025526]\n",
      " [0.10836046 0.11259717 0.0875321  0.09658039 0.09837349 0.1091809\n",
      "  0.10785394 0.08533163 0.09250556 0.10168429]\n",
      " [0.10016508 0.11013372 0.09674689 0.08485249 0.1039256  0.11640369\n",
      "  0.09806732 0.0968081  0.09505638 0.09784068]\n",
      " [0.10243152 0.1257036  0.09108608 0.07206966 0.09836797 0.10863233\n",
      "  0.09499454 0.09641971 0.10857227 0.10172234]\n",
      " [0.09834696 0.11967158 0.0985497  0.08031284 0.10670077 0.10281143\n",
      "  0.09728666 0.08703581 0.10278548 0.10649876]\n",
      " [0.10020785 0.11033167 0.09415196 0.09257228 0.09586532 0.09987062\n",
      "  0.10828701 0.10041013 0.09647758 0.10182558]\n",
      " [0.10475697 0.11001687 0.09118494 0.08627282 0.10879987 0.10953281\n",
      "  0.09702894 0.09164013 0.09468928 0.10607737]\n",
      " [0.10087382 0.10602916 0.0969969  0.08390378 0.1125932  0.08822091\n",
      "  0.10493425 0.0934778  0.09781115 0.115159  ]\n",
      " [0.10278251 0.11265404 0.11021947 0.08980498 0.10317067 0.09886682\n",
      "  0.10262485 0.08922906 0.1023866  0.08826095]\n",
      " [0.09339449 0.10858458 0.09938611 0.09887042 0.10284605 0.11200305\n",
      "  0.10551691 0.09578197 0.08883774 0.09477873]\n",
      " [0.1071026  0.10437061 0.1088472  0.08592763 0.10832336 0.09034192\n",
      "  0.10004323 0.09129889 0.09356616 0.11017836]\n",
      " [0.09713693 0.10092055 0.10644934 0.07666536 0.09876481 0.11250495\n",
      "  0.09076004 0.0967709  0.11500163 0.10502551]\n",
      " [0.10667957 0.11228247 0.09767514 0.08290559 0.10180178 0.10332599\n",
      "  0.10650896 0.09647927 0.09356338 0.09877782]\n",
      " [0.10168395 0.10708179 0.10178454 0.09085273 0.10064376 0.10641853\n",
      "  0.10051563 0.09318147 0.09688458 0.100953  ]\n",
      " [0.09254842 0.11431415 0.09277271 0.08359426 0.09845828 0.11076406\n",
      "  0.0897338  0.10799472 0.10366513 0.10615449]\n",
      " [0.10690831 0.1161408  0.10280411 0.09611326 0.09229432 0.1008893\n",
      "  0.09096903 0.09357256 0.10184907 0.09845919]\n",
      " [0.08986474 0.12260128 0.08819921 0.08751576 0.10319257 0.10462377\n",
      "  0.09733354 0.09545124 0.10520239 0.10601546]\n",
      " [0.10023558 0.10800466 0.11166462 0.08391463 0.09413171 0.11178955\n",
      "  0.11402138 0.09256133 0.09429757 0.08937899]\n",
      " [0.08581711 0.11724392 0.09686147 0.08410811 0.09364606 0.11793716\n",
      "  0.0998144  0.0927108  0.09791364 0.11394729]\n",
      " [0.10340469 0.10689341 0.09558094 0.07627311 0.10573142 0.1019289\n",
      "  0.10546567 0.08812013 0.09952062 0.11708117]\n",
      " [0.11586777 0.11210165 0.09369685 0.09875696 0.10721322 0.10720576\n",
      "  0.0978611  0.08443861 0.09585706 0.08700098]\n",
      " [0.09880641 0.11907986 0.09860751 0.09633194 0.10841072 0.09788094\n",
      "  0.09192925 0.09244049 0.10470091 0.09181199]\n",
      " [0.10208604 0.1144757  0.08647084 0.09466672 0.11470036 0.09954372\n",
      "  0.09278632 0.10301756 0.0994032  0.0928496 ]\n",
      " [0.09988359 0.11819057 0.09457618 0.09472705 0.10842532 0.09539792\n",
      "  0.08712775 0.09089706 0.10329939 0.10747523]\n",
      " [0.08652417 0.10632809 0.09506267 0.09160211 0.10169437 0.124222\n",
      "  0.10201021 0.10145208 0.09548485 0.0956194 ]\n",
      " [0.10322043 0.0998387  0.09118479 0.09114984 0.10561612 0.11200854\n",
      "  0.10597107 0.09199403 0.09750294 0.10151349]\n",
      " [0.10093084 0.11554332 0.09612483 0.09947263 0.09387279 0.11250906\n",
      "  0.09481125 0.08156259 0.10247923 0.10269345]\n",
      " [0.09263235 0.12854937 0.10245904 0.09380613 0.10035878 0.10054719\n",
      "  0.10464782 0.08728854 0.08383279 0.10587801]\n",
      " [0.09757497 0.11382362 0.09388536 0.1024401  0.10405731 0.0970271\n",
      "  0.09759563 0.0926685  0.10258529 0.09834216]\n",
      " [0.10652363 0.11056062 0.09119841 0.0875821  0.10391844 0.10452832\n",
      "  0.10669299 0.09507704 0.09240701 0.10151145]\n",
      " [0.08748525 0.11118368 0.09393441 0.09335499 0.09290419 0.1300112\n",
      "  0.09715647 0.08178493 0.10484894 0.10733596]\n",
      " [0.10979869 0.10280701 0.09865858 0.08888391 0.10455325 0.10226791\n",
      "  0.1019901  0.09324651 0.10428607 0.09350793]\n",
      " [0.10875247 0.11617958 0.08936926 0.09457038 0.0966912  0.10206486\n",
      "  0.10070643 0.09404925 0.09572708 0.10188948]\n",
      " [0.09932822 0.10554571 0.09510717 0.08669095 0.09553942 0.1047477\n",
      "  0.1049695  0.1004874  0.09784985 0.10973404]\n",
      " [0.10491482 0.10637255 0.09996437 0.08825867 0.10890029 0.10200166\n",
      "  0.09653473 0.089106   0.10054159 0.10340533]\n",
      " [0.11381061 0.11867527 0.09143645 0.09134201 0.09377111 0.10404937\n",
      "  0.0912649  0.09984934 0.09651505 0.09928589]\n",
      " [0.11349076 0.09742511 0.0868502  0.08655241 0.10366596 0.10681147\n",
      "  0.09480347 0.10521828 0.10666779 0.09851453]\n",
      " [0.10416801 0.10643417 0.09702919 0.10029051 0.09508424 0.09653151\n",
      "  0.09160874 0.10129599 0.10609415 0.10146344]\n",
      " [0.0987118  0.1224565  0.09713852 0.08894484 0.10865091 0.10903316\n",
      "  0.09436087 0.08667663 0.09456521 0.09946156]\n",
      " [0.10042975 0.12224119 0.10356556 0.08473644 0.09156196 0.11214779\n",
      "  0.09665075 0.09595339 0.09793147 0.09478177]\n",
      " [0.09888807 0.12022208 0.09195025 0.08169781 0.10436838 0.10527249\n",
      "  0.09316307 0.09231178 0.11139482 0.1007313 ]\n",
      " [0.09881283 0.10427482 0.09897846 0.09387273 0.11311118 0.09710164\n",
      "  0.09405272 0.09853964 0.103428   0.09782803]\n",
      " [0.10508554 0.11078022 0.1008449  0.08184007 0.10319545 0.10748982\n",
      "  0.09988827 0.09153324 0.09543248 0.10391002]\n",
      " [0.10905354 0.10850707 0.09490762 0.08511858 0.09959868 0.11471093\n",
      "  0.08986925 0.09929104 0.09192598 0.10701728]\n",
      " [0.09079757 0.10580882 0.1006953  0.09558433 0.09984199 0.10579909\n",
      "  0.10108367 0.09762204 0.09988883 0.10287838]\n",
      " [0.10146687 0.12073194 0.08970529 0.09527291 0.10221308 0.0967517\n",
      "  0.09702721 0.0849999  0.10653542 0.10529571]\n",
      " [0.09677304 0.11827381 0.09363665 0.09292066 0.10838618 0.09343599\n",
      "  0.10051506 0.09407075 0.10192054 0.10006728]\n",
      " [0.10957418 0.10542568 0.10386717 0.08041321 0.09592134 0.10018396\n",
      "  0.10422064 0.09639123 0.10973231 0.09427019]\n",
      " [0.10320126 0.11416332 0.10455741 0.08661493 0.09984351 0.1033752\n",
      "  0.09398574 0.09705625 0.09803372 0.09916871]\n",
      " [0.11127881 0.10428372 0.08898026 0.08769506 0.10550175 0.10798427\n",
      "  0.09693365 0.10089212 0.09618188 0.10026854]\n",
      " [0.10323582 0.10146413 0.10375234 0.08884238 0.1042892  0.10795736\n",
      "  0.09400181 0.09154672 0.1033292  0.10158104]\n",
      " [0.10064028 0.10649301 0.1024373  0.08678475 0.10556543 0.09852686\n",
      "  0.10193706 0.09970611 0.10217573 0.09573349]\n",
      " [0.08910871 0.11840506 0.09270113 0.08765247 0.10563268 0.10034505\n",
      "  0.1036514  0.0962675  0.09107732 0.11515868]\n",
      " [0.11185558 0.10087984 0.09915812 0.08924554 0.10407971 0.11347093\n",
      "  0.08634723 0.08991237 0.10524558 0.09980504]\n",
      " [0.1022825  0.11643723 0.10236101 0.09440827 0.09438109 0.10599089\n",
      "  0.09229001 0.09307619 0.10708002 0.09169286]\n",
      " [0.09848916 0.12476432 0.10759278 0.09073982 0.09258508 0.09923044\n",
      "  0.08868972 0.09045064 0.10505271 0.10240533]\n",
      " [0.09400614 0.10960133 0.10334203 0.08222506 0.10905366 0.1115649\n",
      "  0.09427819 0.08843476 0.10685757 0.10063644]\n",
      " [0.10060155 0.10458852 0.09307873 0.08860099 0.10412836 0.1118139\n",
      "  0.10923617 0.10216516 0.09396387 0.09182283]\n",
      " [0.1063119  0.10456466 0.10815407 0.08268929 0.0960892  0.09573244\n",
      "  0.10584171 0.08451883 0.11235666 0.10374124]\n",
      " [0.11812646 0.1059175  0.09229953 0.08068249 0.09944671 0.11252273\n",
      "  0.09445687 0.08266863 0.10977552 0.10410354]\n",
      " [0.11544842 0.11646268 0.08665268 0.08831151 0.09711589 0.09980527\n",
      "  0.09493168 0.08151655 0.09701899 0.12273636]\n",
      " [0.10158753 0.09834757 0.11082043 0.09229454 0.09402107 0.10117044\n",
      "  0.10980175 0.08836681 0.09839728 0.1051925 ]\n",
      " [0.10204438 0.1128066  0.09214006 0.09296104 0.09820029 0.10061638\n",
      "  0.08552206 0.09071787 0.10970557 0.11528583]\n",
      " [0.09442958 0.12243722 0.09926018 0.08263259 0.09663109 0.11311053\n",
      "  0.08916863 0.10082765 0.10424381 0.09725875]\n",
      " [0.09808821 0.11071398 0.09615991 0.09543268 0.10205761 0.0949564\n",
      "  0.10254209 0.10045733 0.10132944 0.09826235]\n",
      " [0.11477123 0.10455569 0.08726351 0.09062716 0.1106276  0.09335293\n",
      "  0.09452    0.08894834 0.10388415 0.11144935]\n",
      " [0.09298613 0.12519027 0.09211589 0.08042702 0.08793478 0.11271796\n",
      "  0.08490548 0.11104038 0.10466447 0.10801759]\n",
      " [0.10743137 0.10153595 0.09562317 0.08494786 0.10916986 0.10784753\n",
      "  0.09081712 0.08818229 0.10860304 0.10584187]\n",
      " [0.11861624 0.09827806 0.09644278 0.08132624 0.09414259 0.10990834\n",
      "  0.11507091 0.08349102 0.09302027 0.10970353]\n",
      " [0.09953836 0.11017862 0.10649471 0.09331844 0.10227676 0.10396845\n",
      "  0.09705729 0.09126945 0.09934333 0.09655455]\n",
      " [0.10156209 0.11345595 0.08794254 0.09341473 0.09267689 0.11192665\n",
      "  0.10105857 0.09269053 0.11081447 0.09445754]\n",
      " [0.10709418 0.11464365 0.10882246 0.09935995 0.10802019 0.11147249\n",
      "  0.08231442 0.09327438 0.08844763 0.08655056]\n",
      " [0.09893874 0.10458336 0.09245587 0.08829861 0.10552894 0.11258602\n",
      "  0.09281752 0.09626787 0.10166779 0.10685533]\n",
      " [0.09735503 0.10846589 0.10824272 0.0868113  0.09509709 0.09702285\n",
      "  0.09337617 0.10875296 0.09538288 0.10949314]\n",
      " [0.11227594 0.11930715 0.09653075 0.08177442 0.10524326 0.10064717\n",
      "  0.09668422 0.08962449 0.09708321 0.10082934]\n",
      " [0.10990382 0.10333189 0.10490057 0.09347823 0.10116962 0.09122469\n",
      "  0.09974942 0.09701233 0.10039157 0.0988379 ]\n",
      " [0.10975779 0.11120612 0.09619762 0.08867152 0.09445176 0.10359719\n",
      "  0.10688972 0.09290393 0.08956258 0.10676174]\n",
      " [0.10529876 0.1059995  0.08352093 0.08201043 0.10155801 0.11298949\n",
      "  0.10481191 0.1068631  0.10153043 0.09541749]\n",
      " [0.10523529 0.11073629 0.09943989 0.08462202 0.09928397 0.10300975\n",
      "  0.11010461 0.09293362 0.09305713 0.10157742]\n",
      " [0.10334149 0.11333358 0.09378493 0.09403563 0.10323444 0.11303194\n",
      "  0.09862138 0.09178098 0.09314042 0.09569518]\n",
      " [0.09934048 0.11320028 0.09181863 0.07390895 0.13383152 0.07481639\n",
      "  0.09274364 0.10001688 0.11987939 0.10044385]\n",
      " [0.10196576 0.11114297 0.09590376 0.08318739 0.11771168 0.09126598\n",
      "  0.09357708 0.09474649 0.10491402 0.10558489]\n",
      " [0.10487032 0.12377852 0.11035634 0.07510921 0.09786328 0.09383217\n",
      "  0.08712218 0.08981755 0.10428084 0.11296961]\n",
      " [0.09971646 0.12642372 0.09329136 0.09706871 0.09959202 0.09748714\n",
      "  0.10189133 0.0876401  0.09876039 0.09812874]\n",
      " [0.10666241 0.1160413  0.10156751 0.0778103  0.09500864 0.10942041\n",
      "  0.0933722  0.08940554 0.10706224 0.10364947]\n",
      " [0.092636   0.11269449 0.09323475 0.07986926 0.10720043 0.09905677\n",
      "  0.10543515 0.10455376 0.08994352 0.11537591]\n",
      " [0.10239945 0.10061251 0.09045522 0.1097602  0.10467472 0.0956087\n",
      "  0.10725735 0.08969416 0.10342973 0.09610792]\n",
      " [0.11082862 0.10938257 0.09460185 0.09393492 0.08906258 0.10057178\n",
      "  0.10570874 0.09917848 0.09818568 0.09854476]\n",
      " [0.10421356 0.11682921 0.08547968 0.07989747 0.10638072 0.11141416\n",
      "  0.10043422 0.09245319 0.10564164 0.09725625]\n",
      " [0.09989201 0.10289451 0.10128261 0.0876063  0.10225249 0.11075296\n",
      "  0.08483217 0.10834502 0.10067802 0.10146379]\n",
      " [0.10562909 0.10498831 0.09999269 0.08573631 0.09401488 0.09942508\n",
      "  0.11134409 0.11065491 0.09435921 0.09385538]\n",
      " [0.11973388 0.09351718 0.09503797 0.09011804 0.09986392 0.10367752\n",
      "  0.09352573 0.095998   0.10545268 0.10307509]\n",
      " [0.10061304 0.14160922 0.08743567 0.08236509 0.10531007 0.09447187\n",
      "  0.10399313 0.08881283 0.09954367 0.0958454 ]\n",
      " [0.10350198 0.10617647 0.10676315 0.08950615 0.10063682 0.10256819\n",
      "  0.1084602  0.09022164 0.10550465 0.08666073]\n",
      " [0.09977752 0.12371459 0.0922808  0.08559031 0.10194978 0.10544686\n",
      "  0.10205131 0.09036522 0.10004207 0.09878155]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.3229368, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.3229368.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7efefd91ced0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-1\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3072155, step = 1\n",
      "INFO:tensorflow:global_step/sec: 195.452\n",
      "INFO:tensorflow:loss = 2.2945871, step = 101 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.39\n",
      "INFO:tensorflow:loss = 2.2607489, step = 201 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.832\n",
      "INFO:tensorflow:loss = 2.2303114, step = 301 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.896\n",
      "INFO:tensorflow:loss = 2.2056808, step = 401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.188\n",
      "INFO:tensorflow:loss = 2.1660864, step = 501 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.676\n",
      "INFO:tensorflow:loss = 2.1357949, step = 601 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.973\n",
      "INFO:tensorflow:loss = 2.0726595, step = 701 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.947\n",
      "INFO:tensorflow:loss = 1.994842, step = 801 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.215\n",
      "INFO:tensorflow:loss = 1.8981196, step = 901 (0.444 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.8246921.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7efefd91ced0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_classifier.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-02-12-08:36:54\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-1001\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-02-12-08:36:55\n",
      "INFO:tensorflow:Saving dict for global step 1001: accuracy = 0.7648, global_step = 1001, loss = 1.7209345\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1001: /tmp/mnist_convnet_model/model.ckpt-1001\n",
      "{'loss': 1.7209345, 'global_step': 1001, 'accuracy': 0.7648}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=5,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
